AI Developer (LLM) – Technical Task

🎯 Objective:
Build a basic RAG-based chatbot system that accepts user input (text), retrieves relevant content from a set of documents, and responds using an LLM with source references.

📝 Task Overview:
You are required to build a mini AI Query System with the following capabilities:

🔧 Task Requirements

1. Document Ingestion
- Load and process a set of sample documents (5–10 PDFs, DOCX, or TXT files).
- Use any embedding model (OpenAI, SentenceTransformers, Cohere).
- Store embeddings using a vector DB (FAISS, Chroma, or Pinecone).

2. Contextual Query Handling
- Create a basic API or script to accept a user query.
- Retrieve the top 3 most relevant document chunks using vector similarity.
- Use an LLM (OpenAI API or similar) to generate a response using the retrieved content.
- Include citations or reference source filenames in the response.

3. Tech Stack (Recommended)
- Language: Python
- python package manager: UV
- Frameworks: FastAPI
- Vector DB: FAISS or Chroma
- LLM: OpenAI GPT-3.5/GPT-4
- Embeddings:OpenAI
- Document Parsing: PyMuPDF / PyPDF2 / python-docx

4. Bonus (Optional)
- Add basic role-based filters (e.g., if query is made by “Manager”).
- Add a basic frontend (simple HTML/JS UI or Streamlit).
- Add a feedback collection mechanism to log if the response was helpful.

✅ Submission Guidelines
- Host code in a GitHub repository and share the link.
- Include a README file with:
  • Setup instructions
  • Libraries used
  • Sample queries to test
  • Notes on limitations or assumptions
- Optional: Include a Loom video walkthrough (under 3 minutes).

🎯 Evaluation Criteria
- Code clarity and modularity
- Understanding of RAG workflow
- Ability to integrate vector DBs and LLMs
- API structuring and documentation
- Bonus: Creativity in UX or added features

📦 Deliverables
- GitHub repo link
- README.md
- Video walkthrough (mail to akshit.kaushik@originbluy.com)
